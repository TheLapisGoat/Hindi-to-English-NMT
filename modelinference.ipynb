{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import gensim"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2023-07-07 10:58:26.244277: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2023-07-07 10:58:28.409993: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1688727514886
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1688727515048
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hindi_kv = gensim.models.KeyedVectors.load('KeyedVectors/hindi_kv')\n",
        "english_kv = gensim.models.KeyedVectors.load('KeyedVectors/english_kv')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2023-07-07 10:58:34,679 : INFO : loading KeyedVectors object from KeyedVectors/hindi_kv\n2023-07-07 10:58:35,615 : INFO : loading vectors from KeyedVectors/hindi_kv.vectors.npy with mmap=None\n2023-07-07 10:58:49,473 : INFO : KeyedVectors lifecycle event {'fname': 'KeyedVectors/hindi_kv', 'datetime': '2023-07-07T10:58:49.473450', 'gensim': '4.3.1', 'python': '3.10.12 (main, Jul  5 2023, 18:54:27) [GCC 11.2.0]', 'platform': 'Linux-5.15.0-1035-azure-x86_64-with-glibc2.31', 'event': 'loaded'}\n2023-07-07 10:58:49,474 : INFO : loading KeyedVectors object from KeyedVectors/english_kv\n2023-07-07 10:58:49,790 : INFO : loading vectors from KeyedVectors/english_kv.vectors.npy with mmap=None\n2023-07-07 10:58:53,394 : INFO : KeyedVectors lifecycle event {'fname': 'KeyedVectors/english_kv', 'datetime': '2023-07-07T10:58:53.394217', 'gensim': '4.3.1', 'python': '3.10.12 (main, Jul  5 2023, 18:54:27) [GCC 11.2.0]', 'platform': 'Linux-5.15.0-1035-azure-x86_64-with-glibc2.31', 'event': 'loaded'}\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1688727533620
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_SEQ_LEN = 22\n",
        "BATCH_SIZE = 32"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1688727533789
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1688727533975
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hindi_test_data = []\n",
        "english_test_data = []\n",
        "with open(\"Data/test_processed.hi\") as f_input, open(\"Data/test_processed.en\") as f_target:\n",
        "    for input_line, target_line in zip(f_input, f_target):\n",
        "        if input_line == \"\" or target_line == \"\":\n",
        "            continue\n",
        "        input_tokens = word_tokenize(input_line)\n",
        "        target_tokens = word_tokenize(target_line)\n",
        "        if len(input_tokens) > MAX_SEQ_LEN or len(target_tokens) > MAX_SEQ_LEN:\n",
        "            continue\n",
        "        hindi_test_data.append(input_line.strip())\n",
        "        english_test_data.append(target_line.strip())"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1688727628404
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(hindi_test_data)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "61100"
          },
          "metadata": {}
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1688727638274
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import Input, Model\n",
        "from keras.layers import LSTM, Bidirectional, Embedding, Concatenate, Dense, Attention, TimeDistributed\n",
        "from keras.optimizers import Adam\n",
        "tf.keras.backend.clear_session()"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1688727716348
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LATENT_DIM = 256\n",
        "\n",
        "encoder_inputs = Input(shape=(MAX_SEQ_LEN,), name = \"Encoder_Inputs\")\n",
        "enc_emb_layer = Embedding(input_dim=hindi_kv.vectors.shape[0], output_dim=hindi_kv.vectors.shape[1], weights=[hindi_kv.vectors], trainable = False, mask_zero = True, name = \"Encoder_Embedding_Layer\")\n",
        "enc_emb = enc_emb_layer(encoder_inputs)\n",
        "encoder_lstm = LSTM(LATENT_DIM, return_sequences = True, return_state=True, name = \"Encoder_STM_Layer\")\n",
        "\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
        "\n",
        "concat_layer = Concatenate(name = \"Concatenate_Layer\")\n",
        "\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "decoder_inputs = Input(shape = (MAX_SEQ_LEN,), name = \"Decoder_Inputs\")\n",
        "dec_emb_layer = Embedding(input_dim=english_kv.vectors.shape[0], output_dim=english_kv.vectors.shape[1], weights=[english_kv.vectors], trainable = True, mask_zero = True, name = \"Decoder_Embedding_Layer\")\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "decoder_lstm = LSTM(LATENT_DIM, return_sequences=True, return_state=True, name = \"Decoder_LSTM_Layer\")\n",
        "\n",
        "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state = encoder_states)\n",
        "decoder_attention_layer = Attention(name = \"Attention_Layer\")\n",
        "attn_outputs = decoder_attention_layer([decoder_outputs, encoder_outputs])\n",
        "\n",
        "attn_decoder_outputs = concat_layer([decoder_outputs, attn_outputs])\n",
        "\n",
        "decoder_dense = TimeDistributed(Dense(english_kv.vectors.shape[0], activation='softmax'), name = \"Dense_Layer\")\n",
        "final_outputs = decoder_dense(attn_decoder_outputs)\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], final_outputs)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2023-07-07 11:02:03.220629: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10766 MB memory:  -> device: 0, name: Tesla K80, pci bus id: 0001:00:00.0, compute capability: 3.7\n2023-07-07 11:02:03.506762: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 600263200 exceeds 10% of free system memory.\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1688727726119
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights('lstmModelWeights/model.h5')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2023-07-07 11:02:54.963282: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 600263200 exceeds 10% of free system memory.\n2023-07-07 11:02:55.437910: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 819208192 exceeds 10% of free system memory.\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1688727776214
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#encoder model\n",
        "encoder_model = Model(encoder_inputs, [encoder_outputs, state_h, state_c])\n",
        "\n",
        "#inference decoder model\n",
        "inf_decoder_input = Input(shape = (1,))\n",
        "inf_decoder_input_emb = dec_emb_layer(inf_decoder_input)\n",
        "\n",
        "inf_decoder_state_h = Input(shape = (LATENT_DIM,))\n",
        "inf_decoder_state_c = Input(shape = (LATENT_DIM,))\n",
        "\n",
        "inf_encoder_outputs = Input(shape = (MAX_SEQ_LEN, LATENT_DIM,))\n",
        "\n",
        "inf_decoder_output, inf_state_h_output, inf_state_c_output = decoder_lstm(inf_decoder_input_emb, initial_state = [inf_decoder_state_h, inf_decoder_state_c])\n",
        "\n",
        "inf_context_vector = decoder_attention_layer([inf_decoder_output, inf_encoder_outputs])\n",
        "inf_output_with_attention = concat_layer([inf_decoder_output, inf_context_vector])\n",
        "\n",
        "inf_decoder_output = decoder_dense(inf_output_with_attention)\n",
        "\n",
        "inf_decoder_model = Model([inf_decoder_input, inf_decoder_state_h, inf_decoder_state_c, inf_encoder_outputs], [inf_decoder_output, inf_state_h_output, inf_state_c_output])"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1688728754570
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_model.summary()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Model: \"model_2\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n Encoder_Inputs (InputLayer)  [(None, 22)]             0         \n                                                                 \n Encoder_Embedding_Layer (Em  (None, 22, 200)          150065800 \n bedding)                                                        \n                                                                 \n Encoder_STM_Layer (LSTM)    [(None, 22, 256),         467968    \n                              (None, 256),                       \n                              (None, 256)]                       \n                                                                 \n=================================================================\nTotal params: 150,533,768\nTrainable params: 467,968\nNon-trainable params: 150,065,800\n_________________________________________________________________\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1688728757603
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inf_decoder_model.summary()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Model: \"model_3\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_5 (InputLayer)           [(None, 1)]          0           []                               \n                                                                                                  \n Decoder_Embedding_Layer (Embed  multiple            40000400    ['input_5[0][0]']                \n ding)                                                                                            \n                                                                                                  \n input_6 (InputLayer)           [(None, 256)]        0           []                               \n                                                                                                  \n input_7 (InputLayer)           [(None, 256)]        0           []                               \n                                                                                                  \n Decoder_LSTM_Layer (LSTM)      multiple             365568      ['Decoder_Embedding_Layer[2][0]',\n                                                                  'input_6[0][0]',                \n                                                                  'input_7[0][0]']                \n                                                                                                  \n input_8 (InputLayer)           [(None, 22, 256)]    0           []                               \n                                                                                                  \n Attention_Layer (Attention)    multiple             0           ['Decoder_LSTM_Layer[2][0]',     \n                                                                  'input_8[0][0]']                \n                                                                                                  \n Concatenate_Layer (Concatenate  multiple            0           ['Decoder_LSTM_Layer[2][0]',     \n )                                                                'Attention_Layer[2][0]']        \n                                                                                                  \n Dense_Layer (TimeDistributed)  multiple             205202052   ['Concatenate_Layer[2][0]']      \n                                                                                                  \n==================================================================================================\nTotal params: 245,568,020\nTrainable params: 245,568,020\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"
        }
      ],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1688728759512
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_input_sequence(input_line):\n",
        "    input_tokens = word_tokenize(input_line)\n",
        "    input_tokens = ['<sos>'] + input_tokens + ['<eos>']\n",
        "    for idx, token in enumerate(input_tokens):\n",
        "        if token in hindi_kv:\n",
        "            input_tokens[idx] = hindi_kv.key_to_index[token]\n",
        "        else:\n",
        "            input_tokens[idx] = hindi_kv.key_to_index['<unk>']        \n",
        "    input_tokens = input_tokens + [hindi_kv.key_to_index['<pad>']] * (MAX_SEQ_LEN - len(input_tokens))\n",
        "    input_tokens = np.expand_dims(input_tokens, axis = 0)\n",
        "    return input_tokens"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1688728817558
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predicted_sequence(input_seq):\n",
        "    enc_out, s_h, s_c = encoder_model.predict(input_seq, verbose = 0)\n",
        "\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    target_seq[0, 0] = english_kv.key_to_index['<sos>']\n",
        "\n",
        "    stop_flag = False\n",
        "    predicted_seq = []\n",
        "\n",
        "    while not stop_flag:\n",
        "        dec_output, s_h, s_c = inf_decoder_model.predict([target_seq, s_h, s_c, enc_out], verbose = 0)\n",
        "\n",
        "        max_idx = np.argmax(dec_output)\n",
        "        predicted_seq.append(max_idx)\n",
        "\n",
        "        target_seq[0, 0] = max_idx\n",
        "\n",
        "        if max_idx == english_kv.key_to_index['<eos>'] or len(predicted_seq) == MAX_SEQ_LEN:\n",
        "            stop_flag = True\n",
        "\n",
        "    return predicted_seq\n",
        "    \n",
        "def get_english_translation(predicted_seq):\n",
        "    translation = []\n",
        "    for token in predicted_seq:\n",
        "        if token == english_kv.key_to_index['<eos>']:\n",
        "            break\n",
        "        translation.append(english_kv.index_to_key[token])\n",
        "\n",
        "    translation = \" \".join(translation)\n",
        "\n",
        "    return translation\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 84,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1688729932201
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_references = english_test_data"
      ],
      "outputs": [],
      "execution_count": 80,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1688729685702
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = [get_input_sequence(line) for line in hindi_test_data]"
      ],
      "outputs": [],
      "execution_count": 81,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1688729722100
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hypothesis = []\n",
        "references = []\n",
        "for idx, sequence in enumerate(input_sequences):\n",
        "    hypothesis.append(get_english_translation(get_predicted_sequence(sequence)))\n",
        "    references.append(english_test_data[idx])\n",
        "    if idx % 500 == 0:\n",
        "        print(idx)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": true
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1688753751253
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import corpus_bleu, sentence_bleu\n",
        "from nltk.translate.bleu_score import SmoothingFunction\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "from nltk.translate.nist_score import corpus_nist"
      ],
      "outputs": [],
      "execution_count": 223,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1688755614653
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hypothesis1 = [line.split() for line in hypothesis]\n",
        "references1 = [line.split() for line in references]"
      ],
      "outputs": [],
      "execution_count": 215,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1688755517237
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "meteor_scores = []\n",
        "for idx, _ in enumerate(hypothesis1):\n",
        "    meteor_scores.append(meteor_score([references1[idx]], hypothesis1[idx]))"
      ],
      "outputs": [],
      "execution_count": 172,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1688754852585
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(meteor_scores)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 177,
          "data": {
            "text/plain": "0.30459389894137345"
          },
          "metadata": {}
        }
      ],
      "execution_count": 177,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1688754882265
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chencherry = SmoothingFunction()"
      ],
      "outputs": [],
      "execution_count": 179,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1688755134865
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bleu_score = corpus_bleu(references1, hypothesis1, smoothing_function = chencherry.method5, weights = (1, 0, 0, 0))"
      ],
      "outputs": [],
      "execution_count": 212,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1688755336769
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(bleu_score)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "0.24610628949157196\n"
        }
      ],
      "execution_count": 213,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1688755336946
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "tfgpu",
      "language": "python",
      "display_name": "Python (tf-cudnn8.6)"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "tfgpu"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}